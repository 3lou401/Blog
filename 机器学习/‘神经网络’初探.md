>* 感知器
>* 激活函数
>* 神经网络
>* 小结

本文从感知器开始讲起，引入激活函数，最后引出了神经网络的基本概念和思想，希望能帮助读者对神经网络有一个初步的了解！

# 感知器
**人工神经网络的第一个里程碑是感知机perceptron**， 但感知器本质上是用来决策的。 一个感知机其实是对神经元最基本概念的模拟 ，都未必有多少网络概念，他就是一个自动做决策的机器。

感知器纯粹从数学的角度的上看，其实就可以理解为一个黑盒函数，接受若干个输入，产生一个输出的结果，这个结果就代表了感知器所作出的决策！
![image.png](http://upload-images.jianshu.io/upload_images/1234352-ac1b4878f4cd7627.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

举一个简单的例子，假设我们需要判断小明同学是否喜欢一个女生，主要考虑有以下三个因素，女生的颜值(0-10分)，女生的身材(0-10分)，女生的性格(0-10分)，那么对于一个女生我们只需要将这三个因素量化出来，输入到感知器中，然后就能得到感知器给我们决策的结果。而感知器内部决策的原理，其实就是给不同的因素赋予不同的权重，因为不同的因素的重要性对小明来说，自然是不相同的。然后设置一个阈值，如果加权计算之后的结果大于等于这个阈值，就说明可以判断为喜欢，否则则是不喜欢！所以感知器本质上就是一个通过加权计算函数进行决策的工具！
![image.png](http://upload-images.jianshu.io/upload_images/1234352-3f26077775b827db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

根据上面这个公式，我们可以进一步简化，将阈值移到不等式的一边，并且将其称为偏移，那么所有的问题就统一成了一个‘阈值’为0的问题！
![image.png](http://upload-images.jianshu.io/upload_images/1234352-da07e19a87fd741c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
**偏移的意义其实就是阈值，你可以将偏移想象成使感知器如何更容易输出 1，或者用更加生物学术语，偏移是指衡量感知器触发的难易程度。对于一个大的偏移，感知器更容易输出 1。如果偏移负值很大，那么感知器将很难输出 1。**
实际应用中的感知器模型往往更加复杂，如下图所示：
![image.png](http://upload-images.jianshu.io/upload_images/1234352-99094b0ac37a4463.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 激活函数
感知器的学习过程就是通过改变感知器内部的权重和偏移，以使其的输出结果符合期望！但我们仔细观察前文的感知器模型，可以发现，每个感知器的输出可以看作是一个阶跃函数
![image.png](http://upload-images.jianshu.io/upload_images/1234352-e4534d6de98ee2d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
只有两种输出结果，要么是0，要么是1
问题就出现了，这样的话，感知器似乎就变成了一个离散的函数！，如果我们稍微改变权重或者偏移，得到的结果就是要么不变，要么就感知器的输出彻底相反。而我们原本期望的是，每个感知器都对输出结果有一定的比重的贡献，单个感知器权重或偏移的变化应该是对输出结果产生微小影响的，而不是剧变。
![image.png](http://upload-images.jianshu.io/upload_images/1234352-092d9017c89196e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
另一方面来讲，感知器模型本质上恶意理解为函数的拟合，如果感知器的输出都是离散的二元状态，并且是前文简单的加权形式，也就是线性的，那么只能进行线性的拟合，不具备处理非线性问题的能力！
所以这个时候激活函数就出现了，激活函数就是在感知器加权计算之后，再输入到激活函数中进行计算，得到一个输出！
我们以常见的激活函数sigmoid函数为例，
![image.png](http://upload-images.jianshu.io/upload_images/1234352-299e8fd26feff5aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
加入激活函数之后，每个感知器的函数实际上就变成了如下形式
![image.png](http://upload-images.jianshu.io/upload_images/1234352-89790ba63f0c4b67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
我们观察一下，此时感知器函数的图像
![image.png](http://upload-images.jianshu.io/upload_images/1234352-8c4ae1e4706f0748.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
可以对比前文的阶跃的输出图像，我们将一个离散的输出变为一个连续的非线性的输出结果！同时，单个感知器权重和偏移的细微改变，只会对输出结果产生相应的平滑的影响，而不是阶跃式的影响！跟做人一样的道理，不要太武断，太极端，未加入激活函数的感知器模型，就属于非常极端的，要么0，要么1。而加入激活函数后，会是一个在0~1之间的值。

# 激活函数的理论解释
**激活函数是用来加入非线性因素的，解决线性模型所不能解决的问题。**
假设这么一个情景：
我们有这个需求，就是二分类问题，如我要将下面的三角形和圆形点进行正确的分类，如下图：
![image.png](http://upload-images.jianshu.io/upload_images/1234352-c9123094d6158096.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
利用我们单层的感知机, 用它可以划出一条线, 把平面分割开：
![image.png](http://upload-images.jianshu.io/upload_images/1234352-eeb2ce97bbdb540b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
该感知器实现预测的功能步骤如下，就是我已经训练好了一个感知器模型，后面对于要预测的样本点，带入模型中，如果y>0,那么就说明是直线的右侧，也就是正类（我们这里是三角形），如果y<0,那么就说明是直线的左侧，也就是负类（我们这里是圆形

好吧，很容易能够看出，我给出的样本点根本不是线性可分的，一个感知器无论得到的直线怎么动，都不可能完全正确的将三角形与圆形区分出来，那么我们很容易想到用多个感知器来进行组合，以便获得更大的分类问题，好的，下面我们上图，看是否可行：
![image.png](http://upload-images.jianshu.io/upload_images/1234352-16ce6b2ca3f37f33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
好的，我们已经得到了多感知器分类器了，那么它的分类能力是否强大到能将非线性数据点正确分类开呢~我们来分析一下：

我们能够得到
![image.png](http://upload-images.jianshu.io/upload_images/1234352-e41caefeef4a0d3a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
化简后就是
![image.png](http://upload-images.jianshu.io/upload_images/1234352-996ff865d32141dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

不管它怎么组合，最多就是线性方程的组合，最后得到的分类器本质还是一个线性方程，该处理不了的非线性问题，它还是处理不了。

所以如果没有激活函数，那么感知器模型实际上就是在拟合一个线性方程而已，这样的话，能够解决的问题，自然就是太局限了！

激活函数的作用就出来了，将一个线性的函数变为一个非线性的函数！我们依然以最常用的sigmoid激活函数为例：
![image.png](http://upload-images.jianshu.io/upload_images/1234352-19861723103250c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
通过这个激活函数映射之后，输出很明显就是一个非线性函数！能不能解决一开始的非线性分类问题不清楚，但是至少说明有可能啊，上面不加入激活函数神经网络压根就不可能解决这个问题~

同理，扩展到多个神经元组合的情况时候，表达能力就会更强~对应的组合图如下：（现在已经升级为三个非线性感知器在组合了）

![image.png](http://upload-images.jianshu.io/upload_images/1234352-94a2ffc7ec27425a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

最后再通过最优化损失函数的做法，我们能够学习到不断学习靠近能够正确分类三角形和圆形点的曲线，到底会学到什么曲线，不知道到底具体的样子，也许是下面这个~

![image.png](http://upload-images.jianshu.io/upload_images/1234352-08dc21cd9a713f80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


所以到这里为止，我们就解释了这个观点，加入激活函数是用来加入非线性因素的，解决线性模型所不能解决的问题。

# 神经网络
介绍了感知器和激活函数，实际上我们已经将神经网络的基本概念了解的差不多了。将感知器套上激活函数实际上就是神经网络。
和感知器模型一样，神经网络的基本单位是神经元，每个神经元分别接受输入和输出，但与感知器不同的是，除了进行加权计算，还需要利用激活函数输出！

假如我们有如下网络：
![image.png](http://upload-images.jianshu.io/upload_images/1234352-7bad970c59810451.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

就像先前说的，网络的最左边一层被称为输入层，其中的神经元被称为输入神经元。最右边及输出层包含输出神经元，在这个例子中，只有一个单一的输出神经元。中间层被称为隐含层，因为里面的神经元既不是输入也不是输出。“隐含”这个术语可能听起来很神秘——当我第一次听到时候觉得一定有深层的哲学或者数学意义——但实际上它只表示“不是输入和输出”而已。上面的网络只包含了唯一个隐含层，但是一些网络可能有多层。比如，下面的4层网络具有2个隐含层：
![image.png](http://upload-images.jianshu.io/upload_images/1234352-1e1c68927a8bd0e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

神经网络的基本思想就是建立在感知器和激活函数上的。对于多个输入，在神经网络经过多个神经元计算之后，得到多个或者单个输出。检查输出结果是否与期望的一致，如果不一致，就对神经网络中神经元的权重进行调整，我们已经知道，神经元权重的细微调整会引起输出结果的细微变化，这样多个神经元组合起来，逐渐调整，直到符合预期的输出结果，我们就可以认为神经网络训练成功了！这里所说的训练调整的方法，利用到了[*梯度下降法*](https://liuchi.coding.me/2018/01/17/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/)，对神经网络进行反向传播，我们将在后续的文章进行详细的介绍!

# 小结
本文从感知器模型开始，继而引入激活函数，最后引出了神经网络的基本结构和思想，后续将会详细介绍神经网络自主学习的原理！

# Further reading
* [*Neural Networks and Deep Learning*](http://neuralnetworksanddeeplearning.com/index.html)
* [*Why use activation functions*](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-10.html)
